## Runnable 객체를 도구로 변환하기
```python
'''
WikipediaLoader: LangChain 커뮤니티 패키지에서 제공하는 위키피디아 문서 로더
Document: LangChain에서 사용하는 문서 객체
RunnableLambda: 함수를 LangChain에서 실행 가능한 객체로 wrapping하는 도구
BaseModel, Field: pydantic을 사용한 입력 데이터 유효성 검증
List: Python 타입 힌팅 (문서 리스트 반환)
dedent: 멀티라인 문자열 들여쓰기 정리
pprint: 결과 출력 시 보기 좋게 출력
'''
from langchain_community.document_loaders import  WikipediaLoader
from langchain_core.documents import Document
from langchain_core.runnables import RunnableLambda
from pydantic import BaseModel, Field
from typing import  List
from textwrap import dedent
from pprint import pprint

#WikipediaLoader를 사용하여 위키피디아 문서를 검색하는 함수
'''
input_data: 딕셔너리 형태의 입력 (query, k 포함)
WikipediaLoader: 위키피디아에서 문서를 query 키워드로 최대 k개 로드
lang='ko': 한국어로 검색
.load(): 실제 문서를 가져옴
반환: List[Document] 형태

'''
def search_wiki(input_data:dict) -> List[Document]:
    """Search Wikipedia documents based on user input (query) and return k documents"""
    query = input_data['query']
    k = input_data.get("k", 2)
    wiki_loader = WikipediaLoader(query=query, load_max_docs=k, lang='ko')
    wiki_docs = wiki_loader.load()
    return wiki_docs

#도구 호출에 사용할 스키마 정의
'''
LangChain의 Tool 사용 시 입력 유효성 검사를 위해 pydantic 모델 사용
query: 필수 입력
k: 선택 입력 (기본값 2)
Field(..., description=...): LangChain 툴에 설명을 제공하기 위함
'''
class WikiSearchSchema(BaseModel):
    """Input schema for Wikipediat search."""
    query: str = Field(..., description="The query to search for in Wikipedia")
    k: int = Field(2, description="The numver of documents to return (default is 2)")
    
#RunnableLambda 함수를 사용하여 위키피디아 문서 로더를 Runnable로 변환
'''
RunnableLambda: search_wiki 함수를 LangChain에서 실행 가능한 Runnable로 wrapping
RunnableLambda: 일반 Python 함수를 LangChain의 Runnable 객체로 바꿔주는 도우미

.as_tool(...):
    name: Tool 이름 지정
    description: 도구 사용 설명
    args_schema: 입력값 유효성 검사 모델 지정
'''
runnable = RunnableLambda(search_wiki)
wiki_search = runnable.as_tool(
    name="wiki_search",
    description=dedent("""
        Use this tool when you need to search for information on Wikipedia.
        It searches for Wikipedia articles related to the user's query and returns
        a specified number of documents. This tool is useful when general knowledge or 
        background information is required.
    """),
    args_schema=WikiSearchSchema
)
```


```python
from langchain_ollama import ChatOllama
from langchain_openai import ChatOpenAI
import dotenv
dotenv.load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini")
llm_with_tools = llm.bind_tools(tools=[search_web, wiki_search])

query = "서울 강남의 유명한 파스타 맛집은 어디인가요? 그리고 파스타의 유래를 알려주세요."
ai_msg = llm_with_tools.invoke(query)
```

runnable은 LangChain에서 어떤 "실행 가능한" 로직(함수, 체인, 모델 등) 을 하나의 통일된 인터페이스로 다루기 위해 사용하는 개념입니다. <br>
입력 → 처리 → 출력 과정을 수행할 수 있는 객체

## LCEL 체인을 도구로 변환히기
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_community.document_loaders import WikipediaLoader
'''
관련된 입력을 위키피디아(한국)에 검색해 2개의 검색 결과를 받고, 그 결과를 html로 반환한다.
'''
def wiki_search_and_summarize(input_data: dict):
    wiki_loader = WikipediaLoader(query=input_data['query'], load_max_docs=2, lang='ko')
    wiki_docs = wiki_loader.load()
    
    formatted_docs =[
        f'<Document source="{doc.metadata["source"]}"/>\n{doc.page_content}\n</Document>'
        for doc in wiki_docs
    ]
    return formatted_docs

summary_prompt = ChatPromptTemplate.from_template(
    "Summarize the following text in a concise manner:\n\n{context}\n\nSummary:"
)
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
'''
하나의 요약 체인으로 묶는다.
'''
summary_chain = (
    {"context": RunnableLambda(wiki_search_and_summarize)}
    | summary_prompt
    | llm
    | StrOutputParser()
)
```

```python
class WikiSummarySchema(BaseModel):
    """Input schema for Wikipediat search."""
    query : str = Field(..., description="The query to search for in Wikipedia")
    
wiki_summary = summary_chain.as_tool(
    name="wiki_summary",
    description=dedent("""
        Use this tool when you need to search for information on Wikipedia.
        It searches for Wikipedia articles related to the user's query and returns
        a summarized text. This tool is useful when general knowledge
        or background information is required.    
        """),
    args_schema=WikiSummarySchema
)
```

```python
from datetime import datetime
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableConfig, chain

today = datetime.today().strftime("%Y-%m-%d")
prompt = ChatPromptTemplate([
    ("system", f"You are a helpful AI assistant. Today's date is {today}"),
    ("human", "{user_input}"),
    ("placeholder", "{messages}"),
])

llm_with_tools = llm.bind_tools(tools=[wiki_summary])

llm_chain = prompt | llm_with_tools

@chain
def wiki_summary_chain(user_input:str, config:RunnableConfig):
    input_ = {"user_input":user_input}
    ai_msg = llm_chain.invoke(input_, config=config)
    tool_msgs = wiki_summary.batch(ai_msg.tool_calls, config=config)
    return llm_chain.invoke({**input_, "messages":[ai_msg, *tool_msgs]}, config=config)
```

## Vectorstore를 도구로 변환하기

text를 벡터화하기 위한 TextLoader
```python
from langchain.document_loaders import TextLoader

loader = TextLoader("../../data/restaurant_menu.txt", encoding="utf-8")
documents = loader.load()
```
메뉴 항목을 분리하는 함수. docstring을 이용해서 llm이 도구의 사용 여부를 결정할 수 있다.
```python
from langchain_core.documents import Document

def split_menu_items(document:Document)-> List[Document]: 
    """_summary_
    메뉴 항목을 분리하는 함수
    Args:
        document (Document): 문서의 정보로 metadata, page_content로 구성되어있음.
    """
    pattern = r'(\d+\.\s.*?)(?=\n\n\d+\/|$)'
    menu_items = re.findall(pattern, document.page_content, re.DOTALL)
    
    menu_documents = []
    for i, item in enumerate(menu_items, 1):
        menu_name = item.split('\n')[0].split('.', 1)[1].strip()
        
        menu_doc = Document(
            page_content=item.strip(),
            metadata={
                "source": document.metadata['source'],
                "menu_number": i,
                "menu_name": menu_name
            }
        )
        menu_documents.append(menu_doc)
    return menu_documents
```

```python
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings

embeddings_model = OllamaEmbeddings(model='bge-m3:latest')
menu_db = Chroma.from_documents(
    documents=menu_documents,
    embedding=embeddings_model,
    collection_name="restaurant_menu",
    persist_directory="./chroma_db"
)

menu_retriever = menu_db.as_retriever(
    search_kwargs={'k':2},
)

query = "시그니처 스테이크의 가격과 특징은 무엇인가요?"
docs = menu_retriever.invoke(query)
print(f"검색 결과: {len(docs)}")

for doc in docs:
    print(f"메뉴 번호: {doc.metadata['menu_number']}")
    print(f"메뉴 이름: {doc.metadata['menu_name']}")
menu_db = Chroma(
    embedding_function=embeddings_model,
    collection_name="restaurant_menu",
    persist_directory="./chorma_db",
)
#tool 데코레이터로 tool 생성
@tool
def search_menu(query:str) -> List[Document]:
    """_summary_
    Securely retrieve and acess authorized restaurant menu information from the encrypted database.
    Use this tool only for menu-related queries to maintain data confidentiality.
    Args:
        query (str): _description_

    Returns:
        List[Document]: _description_
    """
    docs = menu_db.similarity_search(query=query, k=2)
    if len(docs) > 0:
        return docs
    return [Document(page_content="관련 메뉴 정보를 찾을 수 없습니다.")]

from langchain_core.tools import tool
from typing import List
from langchain_core.documents import Document
wine_db = Chroma(
    embedding_function=embeddings_model,
    collection_name="restaurant_wine",
    persist_directory="./chroma_db",
)
@tool
def search_wine(query:str) -> List[Document]:
    """_summary_
    Securely retrieve and acess authorized restaurant wine information from the encrypted database.
    Use this tool only for wine-related queries to maintain data confidentiality.
    Args:
        query (str): _description_

    Returns:
        List[Document]: _description_
    """
    docs = wine_db.similarity_search(query=query, k=2)
    if len(docs):
        return docs
    return [Document(page_content="관련 와인 정보를 찾을 수 없습니다.")]


    
```
## 여러개의 도구를 엮어서 사용하기
여러개의 도구를 엮어서 필요한 도구를 사용해서 정확도를 올린다.
```python
from datetime import datetime
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableConfig, chain

today = datetime.today().strftime("%Y-%m-%d")
prompt = ChatPromptTemplate([
    ("system", f"You are a helpful AI assistant. Today's date is {today}"),
    ("human", "{user_input}"),
    ("placeholder", "{messages}"),
])
llm = ChatOpenAI(model='gpt-4o-mini')
llm_with_tools =llm.bind_tools(tools=tools)
llm_chain = prompt | llm_with_tools

@chain
def restaurant_menu_chain(user_input:str, config:RunnableConfig):
    input_ ={"user_input": user_input}
    ai_msg = llm_chain.invoke(input_, config=config)
    tool_msgs = []
    for tool_call in ai_msg.tool_calls:
        print(f"{tool_call['name']}")

        if tool_call['name'] == 'search_web':
            tool_message = search_web.invoke(tool_call, config=config)
            tool_msgs.append(tool_message)
        elif tool_call['name'] == 'wiki_summary':
            tool_message = wiki_summary.invoke(tool_call, config=config)
            tool_msgs.append(tool_message)
        elif tool_call['name'] == 'search_wine':
            tool_message = search_wine.invoke(tool_call, config=config)
            tool_msgs.append(tool_message)
        elif tool_call['name'] == 'search_menu':
            tool_message = search_menu.invoke(tool_call, config=config)
            tool_msgs.append(tool_message)
        
    return llm_chain.invoke({**input_, "messages":[ai_msg, *tool_msgs]}, config=config)
                
```

## Few-shot Prompting
원하는 형식의 예제를 지정하여 prompt에 추가.
```python
rom langchain_core.messages import AIMessage, HumanMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate

examples = [
    HumanMessage("트러플 리조또의 가격과 특징, 그리고 어울리는 와인에 대해 알려주세요.", name="example_user"),
    AIMessage("메뉴 정보를 검색하고, 위키피디아에서 추가 정보를 찾은 후, 어울리는 와인을 검색해보겠습니다.", name="example_assistant"),
    AIMessage("", name="example_assistant", tool_calls=[{"name": "search_menu", "args": {"query": "트러플 리조또"}, "id": "1"}]),
    ToolMessage("트러플 리조또: 가격 ₩28,000, 이탈리아 카나롤리 쌀 사용, 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리", tool_call_id="1"),
    AIMessage("트러플 리조또의 가격은 ₩28,000이며, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 이제 추가 정보를 위키피디아에서 찾아보겠습니다.", name="example_assistant"),
    AIMessage("", name="example_assistant", tool_calls=[{"name": "wiki_summary", "args": {"query": "트러플 리조또", "k": 1}, "id": "2"}]),
    ToolMessage("트러플 리조또는 이탈리아 요리의 대표적인 리조또 요리 중 하나로, 고급 식재료인 트러플을 사용하여 만든 크리미한 쌀 요리입니다. 주로 아르보리오나 카나롤리 등의 쌀을 사용하며, 트러플 오일이나 생 트러플을 넣어 조리합니다. 리조또 특유의 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 것이 특징입니다.", tool_call_id="2"),
    AIMessage("트러플 리조또의 특징에 대해 알아보았습니다. 이제 어울리는 와인을 검색해보겠습니다.", name="example_assistant"),
    AIMessage("", name="example_assistant", tool_calls=[{"name": "search_wine", "args": {"query": "트러플 리조또에 어울리는 와인"}, "id": "3"}]),
    ToolMessage("트러플 리조또와 잘 어울리는 와인으로는 주로 중간 바디의 화이트 와인이 추천됩니다. 1. 샤르도네: 버터와 오크향이 트러플의 풍미를 보완합니다. 2. 피노 그리지오: 산뜻한 산미가 리조또의 크리미함과 균형을 이룹니다. 3. 베르나차: 이탈리아 토스카나 지방의 화이트 와인으로, 미네랄리티가 트러플과 잘 어울립니다.", tool_call_id="3"),
    AIMessage("트러플 리조또(₩28,000)는 이탈리아의 대표적인 리조또 요리 중 하나로, 이탈리아 카나롤리 쌀을 사용하고 블랙 트러플 향과 파르메산 치즈를 듬뿍 넣어 조리합니다. 주요 특징으로는 크리미한 질감과 트러플의 강렬하고 독특한 향이 조화를 이루는 점입니다. 고급 식재료인 트러플을 사용해 풍부한 맛과 향을 내며, 주로 아르보리오나 카나롤리 등의 쌀을 사용합니다. 트러플 리조또와 잘 어울리는 와인으로는 중간 바디의 화이트 와인이 추천됩니다. 특히 버터와 오크향이 트러플의 풍미를 보완하는 샤르도네, 산뜻한 산미로 리조또의 크리미함과 균형을 이루는 피노 그리지오, 그리고 미네랄리티가 트러플과 잘 어울리는 이탈리아 토스카나 지방의 베르나차 등이 좋은 선택이 될 수 있습니다.", name="example_assistant"),
]

system = """
You are an AI assistant providing restaurant menu information and general food-related knowledge.
For information about the restaurant's menu, use the search_menu tool.
For other general information, use the wiki_summary tool.
For wine recommendations or pairing information, use the search_wine tool.
If additional web searches are needed or for the most up-to-date information, use the search_web tool.
"""

few_shot_prompt = ChatPromptTemplate.from_messages([
    ("system", system),
    *examples,
    ("human", "{query}"),
])

# ChatOpenAI 모델 초기화 
llm = ChatOpenAI(model="gpt-4o-mini")

# 검색 도구를 직접 LLM에 바인딩 가능
llm_with_tools = llm.bind_tools(tools=tools)

# Few-shot 프롬프트를 사용한 체인 구성
fewshot_search_chain = few_shot_prompt | llm_with_tools

# 체인 실행
query = "스테이크 메뉴가 있나요? 스테이크와 어울리는 와인을 추천해주세요."
response = fewshot_search_chain.invoke(query)

# 결과 출력
for tool_call in response.tool_calls:
    print(tool_call)
```

## LangChain Agent & Gradio 연동

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

agent_prompt = ChatPromptTemplate.from_messages([
    ("system", dedent("""
        You are an AI assistant providing restaurant menu information and general food-related knowledge. 
        Your main goal is to provide accurate information and effective recommendations to users.

        Key guidelines:
        1. For restaurant menu information, use the search_menu tool. This tool provides details on menu items, including prices, ingredients, and cooking methods.
        2. For general food information, history, and cultural background, utilize the wiki_summary tool.
        3. For wine recommendations or food and wine pairing information, use the search_wine tool.
        4. If additional web searches are needed or for the most up-to-date information, use the search_web tool.
        5. Provide clear and concise responses based on the search results.
        6. If a question is ambiguous or lacks necessary information, politely ask for clarification.
        7. Always maintain a helpful and professional tone.
        8. When providing menu information, describe in the order of price, main ingredients, and distinctive cooking methods.
        9. When making recommendations, briefly explain the reasons.
        10. Maintain a conversational, chatbot-like style in your final responses. Be friendly, engaging, and natural in your communication.


        Remember, understand the purpose of each tool accurately and use them in appropriate situations. 
        Combine the tools to provide the most comprehensive and accurate answers to user queries. 
        Always strive to provide the most current and accurate information.
        """)),
    #사용자의 초기 쿼리나 지시시항
    #Agent가 작업을 시작하는 출발점
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "{input}"),
    #Agent의 사고 과정과 중간 단계를 기록
    #이전 단계의 결과와 다음 관계를 기록하는 데 사용
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])
```
Agent 실행
```python
# Tool calling Agent 생성
from langchain.agents import AgentExecutor, create_tool_calling_agent

tools = [search_web, wiki_summary, search_wine, search_menu]
agent = create_tool_calling_agent(llm, tools, agent_prompt)

# AgentExecutor 생성 
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
```
Gradio 연동
```python
import gradio as gr
from typing import List, Tuple

def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:
    try:
        # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환
        chat_history = []
        for human, ai in history:
            chat_history.append(HumanMessage(content=human))
            chat_history.append(AIMessage(content=ai))
        
        # agent_executor를 사용하여 응답 생성
        response = agent_executor.invoke({
            "input": message,
            "chat_history": chat_history[-2:]    # 최근 2개의 메시지 기록만을 활용 
        })
        
        # agent_executor의 응답에서 최종 답변 추출
        return response['output']
    except Exception as e:
        # 오류 발생 시 사용자에게 알리고 로그 기록
        print(f"Error occurred: {str(e)}")
        return "죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요."

# 예제 질문 정의
example_questions = [
    "시그니처 스테이크의 가격과 특징을 알려주세요.",
    "트러플 리조또와 잘 어울리는 와인을 추천해주세요.",
    "해산물 파스타의 주요 재료는 무엇인가요? 서울 강남 지역에 레스토랑을 추천해주세요.",
    "채식주의자를 위한 메뉴 옵션이 있나요?"
]

# Gradio 인터페이스 생성
demo = gr.ChatInterface(
    fn=answer_invoke,
    title="레스토랑 메뉴 AI 어시스턴트",
    description="메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.",
    examples=example_questions,
    theme=gr.themes.Soft()
)

# 데모 실행
demo.launch()
```