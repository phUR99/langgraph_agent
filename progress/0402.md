1. `pprint()`를 사용할 경우 json 형식의 파일을 깔끔하게 출력할 수 있음.
## Tool Calling
LLM이 외부 함수를 호출하는 기능.
더 정밀하고 실용적인 작업을 수행할 수 있음.
### 도구 직접 실행
query를 자연어의 형태로 `invoke()` method를 통해서 직접적으로 전달.
### Tool Calling
사용자의 질문을 그대로 검색창에 넣어서 검색하는 것이 아닌, 실제 유저가 검색을 하듯이 적절한 검색어로 변환을 해줘서 검색을 수행. <br>
`bind_tools()` ChatGpt 모델 O, Ollama 모델일 경우 되는 경우(**llama.3.1**), 안 되는 경우(**EEVE**, **deepseek**) 있으니 Model Spec.을 참고해서 해야할 듯. <br>
`web_search = TavilySearchResults(max_results=2)` tools를 전달하면 모델은 schema 등 tools의 info.를 전부 가지고 있는 상태. <br>
이후 이런 tools을 [tools]로 list의 형태로 전달. <br>

## Tool Calling 작업 결과를 가지고 검색 작업을 실행하기
### args schema
ai의 msg에서 1st 도구 호출을 가져와 직접 처리
'args'를 사용하고 tool을 호출하고 그 결과를 얻음.
```python
tool_call = ai_msg.tool_calls[0]
web_serach.inkoke(tool_call['args])
```
### tool_call 
도구를 직접 호출하여 `ToolMessage` 객체를 생성
간단하고 직관적인 방법으로, LangChain의 추상화를 활용
```python
tool_message = web_search.invoke(tool_call)
```
### define ToolMessage
도구의 호출 결과를 바탕을 `ToolMessage` 객체를 생성
도구 호출의 ID와 이름을 포함하여 더 구조화된 메시지 생성.
```python
tool_message = ToolMessage(
    content=tool_output,
    tool_call_id=tool_call['id'],
    name=tool_call['name']
)
```